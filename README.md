<h1 align='center'>í…Œë‹ˆìŠ¤ ê²½ê¸° ì˜ìƒ ë¶„ì„(Tennis Vision) ğŸ¾</h1>

## ê°œìš”
í…Œë‹ˆìŠ¤ëŠ” ì „ ì„¸ê³„ì ìœ¼ë¡œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ìŠ¤í¬ì¸  ì¤‘ í•˜ë‚˜ë¡œ, ì„¸ê³„ ìŠ¤í¬ì¸  ìˆœìœ„ì—ì„œ ìƒìœ„ê¶Œì„ ìœ ì§€í•˜ê³  ìˆë‹¤. í•˜ì§€ë§Œ, í…Œë‹ˆìŠ¤ ê²½ê¸°ì˜ ì „ëµì ì¸ ì¸¡ë©´ì„ ë¶„ì„í•˜ê³  í”Œë ˆì´ì–´ì˜ ê¸°ìˆ ì ì¸ ìˆ˜ì¤€ì„ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ëŠ” ê²ƒì€ ì•„ì§ê¹Œì§€ í•œê³„ê°€ ì¡´ì¬í•œë‹¤. í…Œë‹ˆìŠ¤ì˜ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆëŠ” ë§Œí¼, ì„ ìˆ˜ë“¤ë¿ë§Œ ì•„ë‹ˆë¼ ì¼ë°˜ì¸ë“¤ ì—­ì‹œ í…Œë‹ˆìŠ¤ ê²½ê¸°ì— ëŒ€í•´ ë” ì˜ ì´í•´í•˜ê³  ë” ë‚˜ì€ ì „ëµì„ ìˆ˜ë¦½í•  í•„ìš”ê°€ ìˆë‹¤. ë˜í•œ, í…Œë‹ˆìŠ¤ë¥¼ ì¢‹ì•„í•˜ëŠ” ë§ì€ ì´ë“¤ì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ë” ë‚˜ì€ ê²½ê¸°ë ¥ìœ¼ë¡œ í…Œë‹ˆìŠ¤ë¥¼ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê¸°íšŒë¥¼ ë§ˆë ¨í•´ì•¼ í•œë‹¤.<br/>
ì´ë ‡ê²Œ í…Œë‹ˆìŠ¤ë¥¼ ì¦ê¸°ëŠ” ë§ì€ ì´ë“¤ì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ë” ë‚˜ì€ ê²½ê¸°ë ¥ì„ ì§ì ‘ ìˆ˜ë¦½í•  ìˆ˜ ìˆë„ë¡ í•˜ê¸° ìœ„í•´ì„œëŠ” í…Œë‹ˆìŠ¤ ê²½ê¸° ì˜ìƒì„ ë¶„ì„í•´ì•¼ í•œë‹¤. ì „ë¬¸ì ì¸ í…Œë‹ˆìŠ¤ ì„ ìˆ˜ë“¤ì˜ ê²½ê¸° ì˜ìƒì„ ë¶„ì„í•˜ì—¬ ì„ ìˆ˜ë“¤ì˜ ì›€ì§ì„ ë° ìì„¸, ë™ì‘, ì½”íŠ¸ì™€ ê³µì˜ ìœ„ì¹˜ ë“±ì„ ë” ìì„¸íˆ ì œê³µë°›ëŠ”ë‹¤ë©´, ë” ë‚˜ì€ ê²½ê¸° ë°©í–¥ì„ ì§ì ‘ ìˆ˜ë¦½í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì»´í“¨í„° ë¹„ì „ ê¸°ìˆ ê³¼ ë°ì´í„° ë¶„ì„ì„ í†µí•´ í…Œë‹ˆìŠ¤ ê²½ê¸° ì˜ìƒì„ ë¶„ì„í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ê³ ì í•œë‹¤.

## Development Period
2023.09 ~ 2023.12

## ğŸ§‘â€ğŸ¤â€ğŸ§‘Team Members
<ul>
  <li><a href="https://github.com/ryesw">ê¹€ì„±ìš°(Team Leader)</a> @Kim SungWoo</li>
  <li><a href="https://github.com/heejeeong">ë‚¨í¬ì •</a> @Nam HeeJung</li>
  <li><a href="https://github.com/ChaSeongYeon">ì°¨ì„±ì—°</a> @Cha SeongYeon</li>
  <li><a href="https://github.com/hoyoonchoi">ìµœí˜¸ìœ¤</a> @Choi HoYoon</li>
</ul>

## Professor
<ul>
  <li><a href="https://wonhee-lee.github.io/">ì´ì›í¬</a> @Lee WonHee</li>
</ul>

## ğŸ“ŒObjectives
<ul>
  <li>Track two tennis players</li>
  <li>Estimate two players pose</li>
  <li>Classify two players motion</li>
  <li>Detect tennis court lines</li>
  <li>Detect and Track the tennis ball</li>
  <li>Tennis Match Minimap</li>
</ul>

## Data
<ul>
  <li><a href="http://thetis.image.ece.ntua.gr/">THETIS Dataset</a></li>
</ul>

## Result
Input            |  Output
:-------------------------:|:-------------------------:
![input_img1](https://github.com/ryesw/TennisTechPro/tree/main/gif/in_1)  |  ![output_img1](https://github.com/ryesw/TennisTechPro/tree/main/gif/out_1)
![input_img2](https://github.com/ryesw/TennisTechPro/tree/main/gif/in_2)  |  ![output_img2](https://github.com/ryesw/TennisTechPro/tree/main/gif/out_2)
![input_img3](https://github.com/ryesw/TennisTechPro/tree/main/gif/in_5)  |  ![output_img3](https://github.com/ryesw/TennisTechPro/tree/main/gif/out_5)

## How to Run
1. Clone this repository
```git
git clone https://github.com/ryesw/TennisTechPro
```

2. Go to predict_video.py

3. Write your input video path and filename and output path
```python
input_video_path = 'test/video_input1.mp4'
output_video_path = 'output/video1/'
```


## Helpful Repositories
<ul>
  <li><a href="https://github.com/avivcaspi/TennisProject">Tennis Project</a> @avivcaspi</li>
  <li><a href="https://github.com/MaximeBataille/tennis_tracking">Tennis_Tracking</a> @MaximeBataille</li>
  <li><a href="https://github.com/ArtLabss/tennis-tracking">Tennis-Tracking</a> @ArtLabss</li>
  <li><a href="https://github.com/antoinekeller/tennis_shot_recognition">tennis_shot_recognition</a> @antoinekeller</li>
  <li><a href="https://github.com/chow-vincent/tennis_action_recognition">tennis_action_recognition</a> @chow-vincent</li>
  <li><a href="https://nol.cs.nctu.edu.tw:234/open-source/TrackNet/tree/master/Code_Python3">TrackNet</a></li>
  <li><a href="https://github.com/hgupt3/TRACE">TRACE</a> @hgupt3</li>
</ul>
